

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Sample Kismatic YAML file! &mdash; Build-At-Scale 1.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Sample helm chart parameters" href="helm-chart-values.html" />
    <link rel="prev" title="Installing kubernetes using kismatic." href="kubernetes-install.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> Build-At-Scale
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="prerequisites.html">Pre-Requisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="kubernetes-install.html">Installing kubernetes using kismatic.</a></li>
<li class="toctree-l1"><a class="reference internal" href="kubernetes-install.html#installing-build-at-scale">Installing Build-at-Scale</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Sample Kismatic YAML file!</a></li>
<li class="toctree-l1"><a class="reference internal" href="helm-chart-values.html">Sample helm chart parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="uninstall.html">Uninstalling Build-At-Scale</a></li>
<li class="toctree-l1"><a class="reference internal" href="uninstall.html#uninstalling-kismatic-cluster">Uninstalling kismatic cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="support.html">Support for Build-at-Scale:</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Build-At-Scale</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Sample Kismatic YAML file!</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/kismatic-sample-yaml.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="sample-kismatic-yaml-file">
<h1>Sample Kismatic YAML file!<a class="headerlink" href="#sample-kismatic-yaml-file" title="Permalink to this headline">Â¶</a></h1>
<blockquote>
<div><div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cluster</span><span class="p">:</span>
  <span class="n">name</span><span class="p">:</span> <span class="n">kubernetes</span>

  <span class="c1"># Kubernetes cluster version (supported minor version &quot;v1.9.x&quot;).</span>
  <span class="n">version</span><span class="p">:</span> <span class="n">v1</span><span class="o">.</span><span class="mf">9.2</span>

  <span class="c1"># Set to true if the nodes have the required packages installed.</span>
  <span class="n">disable_package_installation</span><span class="p">:</span> <span class="n">false</span>

  <span class="c1"># Set to true if you are performing a disconnected installation.</span>
  <span class="n">disconnected_installation</span><span class="p">:</span> <span class="n">false</span>

  <span class="c1"># Networking configuration of your cluster.</span>
  <span class="n">networking</span><span class="p">:</span>

        <span class="c1"># Kubernetes will assign pods IPs in this range. Do not use a range that is</span>
        <span class="c1"># already in use on your local network!</span>
        <span class="n">pod_cidr_block</span><span class="p">:</span> <span class="mf">172.100</span><span class="o">.</span><span class="mf">0.0</span><span class="o">/</span><span class="mi">16</span>

        <span class="c1"># Kubernetes will assign services IPs in this range. Do not use a range</span>
        <span class="c1"># that is already in use by your local network or pod network!</span>
        <span class="n">service_cidr_block</span><span class="p">:</span> <span class="mf">172.20</span><span class="o">.</span><span class="mf">0.0</span><span class="o">/</span><span class="mi">16</span>

        <span class="c1"># Set to true if your nodes cannot resolve each others&#39; names using DNS.</span>
        <span class="n">update_hosts_files</span><span class="p">:</span> <span class="n">true</span>

        <span class="c1"># Set the proxy server to use for HTTP connections.</span>
        <span class="n">http_proxy</span><span class="p">:</span> <span class="s2">&quot;&quot;</span>

        <span class="c1"># Set the proxy server to use for HTTPs connections.</span>
        <span class="n">https_proxy</span><span class="p">:</span> <span class="s2">&quot;&quot;</span>

        <span class="c1"># List of host names and/or IPs that shouldn&#39;t go through any proxy.</span>
        <span class="c1"># All nodes&#39; &#39;host&#39; and &#39;IPs&#39; are always set.</span>
        <span class="n">no_proxy</span><span class="p">:</span> <span class="s2">&quot;&quot;</span>

  <span class="c1"># Generated certs configuration.</span>
  <span class="n">certificates</span><span class="p">:</span>

        <span class="c1"># Self-signed certificate expiration period in hours; default is 2 years.</span>
        <span class="n">expiry</span><span class="p">:</span> <span class="mi">17520</span><span class="n">h</span>

        <span class="c1"># CA certificate expiration period in hours; default is 2 years.</span>
        <span class="n">ca_expiry</span><span class="p">:</span> <span class="mi">17520</span><span class="n">h</span>

  <span class="c1"># SSH configuration for cluster nodes.</span>
  <span class="n">ssh</span><span class="p">:</span>

        <span class="c1"># This user must be able to sudo without password.</span>
        <span class="n">user</span><span class="p">:</span> <span class="n">kubernetes</span>

        <span class="c1"># Absolute path to the ssh private key we should use to manage nodes.</span>
        <span class="n">ssh_key</span><span class="p">:</span> <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">kubernetes</span><span class="o">/</span><span class="n">kismetic</span><span class="o">/</span><span class="n">app</span><span class="o">-</span><span class="n">linux2</span><span class="o">.</span><span class="n">key</span>
        <span class="n">ssh_port</span><span class="p">:</span> <span class="mi">22</span>

  <span class="c1"># Override configuration of Kubernetes components.</span>
  <span class="n">kube_apiserver</span><span class="p">:</span>
        <span class="n">option_overrides</span><span class="p">:</span> <span class="p">{}</span>

  <span class="n">kube_controller_manager</span><span class="p">:</span>
        <span class="n">option_overrides</span><span class="p">:</span> <span class="p">{}</span>

  <span class="n">kube_scheduler</span><span class="p">:</span>
        <span class="n">option_overrides</span><span class="p">:</span> <span class="p">{}</span>

  <span class="n">kube_proxy</span><span class="p">:</span>
        <span class="n">option_overrides</span><span class="p">:</span> <span class="p">{}</span>

  <span class="n">kubelet</span><span class="p">:</span>
        <span class="n">option_overrides</span><span class="p">:</span>
          <span class="n">cgroup</span><span class="o">-</span><span class="n">driver</span><span class="p">:</span> <span class="s2">&quot;systemd&quot;</span>

  <span class="c1"># Kubernetes cloud provider integration.</span>
  <span class="n">cloud_provider</span><span class="p">:</span>

        <span class="c1"># Options: &#39;aws&#39;,&#39;azure&#39;,&#39;cloudstack&#39;,&#39;fake&#39;,&#39;gce&#39;,&#39;mesos&#39;,&#39;openstack&#39;,</span>
        <span class="c1"># &#39;ovirt&#39;,&#39;photon&#39;,&#39;rackspace&#39;,&#39;vsphere&#39;.</span>
        <span class="c1"># Leave empty for bare metal setups or other unsupported providers.</span>
        <span class="n">provider</span><span class="p">:</span> <span class="s2">&quot;&quot;</span>

        <span class="c1"># Path to the config file, leave empty if provider does not require it.</span>
        <span class="n">config</span><span class="p">:</span> <span class="s2">&quot;&quot;</span>

<span class="c1"># Docker daemon configuration of all cluster nodes.</span>
<span class="n">docker</span><span class="p">:</span>

  <span class="c1"># Set to true if docker is already installed and configured.</span>
  <span class="n">disable</span><span class="p">:</span> <span class="n">false</span>
  <span class="n">logs</span><span class="p">:</span>
        <span class="n">driver</span><span class="p">:</span> <span class="n">json</span><span class="o">-</span><span class="n">file</span>
        <span class="n">opts</span><span class="p">:</span>
          <span class="nb">max</span><span class="o">-</span><span class="n">file</span><span class="p">:</span> <span class="s2">&quot;1&quot;</span>
          <span class="nb">max</span><span class="o">-</span><span class="n">size</span><span class="p">:</span> <span class="mi">50</span><span class="n">m</span>

  <span class="n">storage</span><span class="p">:</span>

        <span class="c1"># Leave empty to have docker automatically select the driver.</span>
        <span class="n">driver</span><span class="p">:</span> <span class="s2">&quot;&quot;</span>
        <span class="n">opts</span><span class="p">:</span> <span class="p">{}</span>

        <span class="c1"># Used for setting up Device Mapper storage driver in direct-lvm mode.</span>
        <span class="n">direct_lvm_block_device</span><span class="p">:</span>

          <span class="c1"># Absolute path to the block device that will be used for direct-lvm mode.</span>
          <span class="c1"># This device will be wiped and used exclusively by docker.</span>
          <span class="n">path</span><span class="p">:</span> <span class="s2">&quot;&quot;</span>
          <span class="n">thinpool_percent</span><span class="p">:</span> <span class="s2">&quot;95&quot;</span>
          <span class="n">thinpool_metapercent</span><span class="p">:</span> <span class="s2">&quot;1&quot;</span>
          <span class="n">thinpool_autoextend_threshold</span><span class="p">:</span> <span class="s2">&quot;80&quot;</span>
          <span class="n">thinpool_autoextend_percent</span><span class="p">:</span> <span class="s2">&quot;20&quot;</span>

<span class="c1"># If you want to use an internal registry for the installation or upgrade, you</span>
<span class="c1"># must provide its information here. You must seed this registry before the</span>
<span class="c1"># installation or upgrade of your cluster. This registry must be accessible from</span>
<span class="c1"># all nodes on the cluster.</span>
<span class="n">docker_registry</span><span class="p">:</span>

  <span class="c1"># IP or hostname and port for your registry.</span>
  <span class="n">server</span><span class="p">:</span> <span class="s2">&quot;https://index.docker.io/v1/&quot;</span>

  <span class="c1"># Absolute path to the certificate authority that should be trusted when</span>
  <span class="c1"># connecting to your registry.</span>
  <span class="n">CA</span><span class="p">:</span> <span class="s2">&quot;&quot;</span>

  <span class="c1"># Leave blank for unauthenticated access.</span>
  <span class="n">username</span><span class="p">:</span> <span class="s2">&quot;&quot;</span>

  <span class="c1"># Leave blank for unauthenticated access.</span>
  <span class="n">password</span><span class="p">:</span> <span class="s2">&quot;&quot;</span>

<span class="c1"># Add-ons are additional components that KET installs on the cluster.</span>
<span class="n">add_ons</span><span class="p">:</span>
  <span class="n">cni</span><span class="p">:</span>
        <span class="n">disable</span><span class="p">:</span> <span class="n">false</span>

        <span class="c1"># Selecting &#39;custom&#39; will result in a CNI ready cluster, however it is up to</span>
        <span class="c1"># you to configure a plugin after the install.</span>
        <span class="c1"># Options: &#39;calico&#39;,&#39;weave&#39;,&#39;contiv&#39;,&#39;custom&#39;.</span>
        <span class="n">provider</span><span class="p">:</span> <span class="n">calico</span>
        <span class="n">options</span><span class="p">:</span>
          <span class="n">calico</span><span class="p">:</span>

                <span class="c1"># Options: &#39;overlay&#39;,&#39;routed&#39;.</span>
                <span class="n">mode</span><span class="p">:</span> <span class="n">overlay</span>

                <span class="c1"># Options: &#39;warning&#39;,&#39;info&#39;,&#39;debug&#39;.</span>
                <span class="n">log_level</span><span class="p">:</span> <span class="n">info</span>

                <span class="c1"># MTU for the workload interface, configures the CNI config.</span>
                <span class="n">workload_mtu</span><span class="p">:</span> <span class="mi">1500</span>

                <span class="c1"># MTU for the tunnel device used if IPIP is enabled.</span>
                <span class="n">felix_input_mtu</span><span class="p">:</span> <span class="mi">1440</span>

  <span class="n">dns</span><span class="p">:</span>
        <span class="n">disable</span><span class="p">:</span> <span class="n">false</span>

        <span class="c1"># Options: &#39;kubedns&#39;,&#39;coredns&#39;.</span>
        <span class="n">provider</span><span class="p">:</span> <span class="n">kubedns</span>

  <span class="n">heapster</span><span class="p">:</span>
        <span class="n">disable</span><span class="p">:</span> <span class="n">true</span>
        <span class="n">options</span><span class="p">:</span>
          <span class="n">heapster</span><span class="p">:</span>
                <span class="n">replicas</span><span class="p">:</span> <span class="mi">2</span>

                <span class="c1"># Specify kubernetes ServiceType. Defaults to &#39;ClusterIP&#39;.</span>
                <span class="c1"># Options: &#39;ClusterIP&#39;,&#39;NodePort&#39;,&#39;LoadBalancer&#39;,&#39;ExternalName&#39;.</span>
                <span class="n">service_type</span><span class="p">:</span> <span class="n">ClusterIP</span>

                <span class="c1"># Specify the sink to store heapster data. Defaults to an influxdb pod</span>
                <span class="c1"># running on the cluster.</span>
                <span class="n">sink</span><span class="p">:</span> <span class="n">influxdb</span><span class="p">:</span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">heapster</span><span class="o">-</span><span class="n">influxdb</span><span class="o">.</span><span class="n">kube</span><span class="o">-</span><span class="n">system</span><span class="o">.</span><span class="n">svc</span><span class="p">:</span><span class="mi">8086</span>

          <span class="n">influxdb</span><span class="p">:</span>

                <span class="c1"># Provide the name of the persistent volume claim that you will create</span>
                <span class="c1"># after installation. If not specified, the data will be stored in</span>
                <span class="c1"># ephemeral storage.</span>
                <span class="n">pvc_name</span><span class="p">:</span> <span class="s2">&quot;&quot;</span>

  <span class="n">dashboard</span><span class="p">:</span>
        <span class="n">disable</span><span class="p">:</span> <span class="n">false</span>

  <span class="n">package_manager</span><span class="p">:</span>
        <span class="n">disable</span><span class="p">:</span> <span class="n">false</span>

        <span class="c1"># Options: &#39;helm&#39;.</span>
        <span class="n">provider</span><span class="p">:</span> <span class="n">helm</span>
        <span class="n">options</span><span class="p">:</span>
          <span class="n">helm</span><span class="p">:</span>
                <span class="n">namespace</span><span class="p">:</span> <span class="n">kube</span><span class="o">-</span><span class="n">system</span>

  <span class="c1"># The rescheduler ensures that critical add-ons remain running on the cluster.</span>
  <span class="n">rescheduler</span><span class="p">:</span>
        <span class="n">disable</span><span class="p">:</span> <span class="n">false</span>

<span class="c1"># Etcd nodes are the ones that run the etcd distributed key-value database.</span>
<span class="n">etcd</span><span class="p">:</span>
  <span class="n">expected_count</span><span class="p">:</span> <span class="mi">1</span>

  <span class="c1"># Provide the hostname and IP of each node. If the node has an IP for internal</span>
  <span class="c1"># traffic, provide it in the internalip field. Otherwise, that field can be</span>
  <span class="c1"># left blank.</span>
  <span class="n">nodes</span><span class="p">:</span>
  <span class="o">-</span> <span class="n">host</span><span class="p">:</span> <span class="s2">&quot;app-linux2.lab.com&quot;</span>
        <span class="n">ip</span><span class="p">:</span> <span class="s2">&quot;10.10.10.10&quot;</span>
        <span class="n">internalip</span><span class="p">:</span> <span class="s2">&quot;&quot;</span>

<span class="c1"># Master nodes are the ones that run the Kubernetes control plane components.</span>
<span class="n">master</span><span class="p">:</span>
  <span class="n">expected_count</span><span class="p">:</span> <span class="mi">1</span>

  <span class="c1"># If you have set up load balancing for master nodes, enter the FQDN name here.</span>
  <span class="c1"># Otherwise, use the IP address of a single master node.</span>
  <span class="n">load_balanced_fqdn</span><span class="p">:</span> <span class="s2">&quot;app-linux2.lab.com&quot;</span>

  <span class="c1"># If you have set up load balancing for master nodes, enter the short name here.</span>
  <span class="c1"># Otherwise, use the IP address of a single master node.</span>
  <span class="n">load_balanced_short_name</span><span class="p">:</span> <span class="s2">&quot;10.10.10.11&quot;</span>
  <span class="n">nodes</span><span class="p">:</span>
  <span class="o">-</span> <span class="n">host</span><span class="p">:</span> <span class="s2">&quot;app-linux2.lab.com&quot;</span>
        <span class="n">ip</span><span class="p">:</span> <span class="s2">&quot;10.10.10.12&quot;</span>
        <span class="n">internalip</span><span class="p">:</span> <span class="s2">&quot;&quot;</span>
        <span class="n">labels</span><span class="p">:</span> <span class="p">{}</span>

<span class="c1"># Worker nodes are the ones that will run your workloads on the cluster.</span>
<span class="n">worker</span><span class="p">:</span>
  <span class="n">expected_count</span><span class="p">:</span> <span class="mi">2</span>
  <span class="n">nodes</span><span class="p">:</span>
  <span class="o">-</span> <span class="n">host</span><span class="p">:</span> <span class="s2">&quot;app-linux1.lab.com&quot;</span>
        <span class="n">ip</span><span class="p">:</span> <span class="s2">&quot;10.10.10.11&quot;</span>
        <span class="n">internalip</span><span class="p">:</span> <span class="s2">&quot;&quot;</span>
        <span class="n">labels</span><span class="p">:</span> <span class="p">{}</span>

  <span class="o">-</span> <span class="n">host</span><span class="p">:</span> <span class="s2">&quot;app-linux3.lab.com&quot;</span>
        <span class="n">ip</span><span class="p">:</span> <span class="s2">&quot;10.10.10.13&quot;</span>
        <span class="n">internalip</span><span class="p">:</span> <span class="s2">&quot;&quot;</span>
        <span class="n">labels</span><span class="p">:</span> <span class="p">{}</span>

<span class="c1"># Ingress nodes will run the ingress controllers.</span>
<span class="n">ingress</span><span class="p">:</span>
  <span class="n">expected_count</span><span class="p">:</span> <span class="mi">1</span>
  <span class="n">nodes</span><span class="p">:</span>
  <span class="o">-</span> <span class="n">host</span><span class="p">:</span> <span class="s2">&quot;app-linux2.lab.com&quot;</span>
        <span class="n">ip</span><span class="p">:</span> <span class="s2">&quot;10.10.10.12&quot;</span>
        <span class="n">internalip</span><span class="p">:</span> <span class="s2">&quot;&quot;</span>
        <span class="n">labels</span><span class="p">:</span> <span class="p">{}</span>

<span class="c1"># Storage nodes will be used to create a distributed storage cluster that can</span>
<span class="c1"># be consumed by your workloads.</span>
<span class="n">storage</span><span class="p">:</span>
  <span class="n">expected_count</span><span class="p">:</span> <span class="mi">0</span>
  <span class="n">nodes</span><span class="p">:</span> <span class="p">[]</span>

<span class="c1"># A set of NFS volumes for use by on-cluster persistent workloads.</span>
<span class="n">nfs</span><span class="p">:</span>
  <span class="n">nfs_volume</span><span class="p">:</span> <span class="p">[]</span>
</pre></div>
</div>
</div></blockquote>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="helm-chart-values.html" class="btn btn-neutral float-right" title="Sample helm chart parameters" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="kubernetes-install.html" class="btn btn-neutral" title="Installing kubernetes using kismatic." accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, NetApp.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'1.0',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>